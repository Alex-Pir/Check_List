<?php
    $MESS["TITLE_PAGE_TEHNIC"] = "ЧЕКЛИСТ ТЕХНИЧЕСКОГО АУДИТА САЙТА";
//Заголовки
    $MESS["MAIN_TITLE"] = "ЧЕКЛИСТ ТЕХНИЧЕСКОГО АУДИТА САЙТА";

//основные чекбоксы
    $MESS["CHECK_1"] = "Robots.txt";
    $MESS["CHECK_2"] = "Sitemap.xml";
    $MESS["CHECK_3"] = "301 редирект";
    $MESS["CHECK_4"] = "404 страница";
    $MESS["CHECK_5"] = "Ошибки 5**";
    $MESS["CHECK_6"] = "HTTP/HTTPS";
    $MESS["CHECK_7"] = "Человеко Понятный Урл (ЧПУ)";
//Информация
    $MESS["MORE_INFORMATION_1"] = "Robots.txt - это специальный файл, расположенный в корневом каталоге сайта. 
                                   Веб-мастер указывает в нем, какие страницы и данные не следует индексироать.
                                   Файл содержит директивы, описыающие доступ к разделам сайта (так называемый стандарт
                                   исключений для роботов). Например, с его помощью можно создать отдельные настройки доступа для поисковых роботов, 
                                   предназначенных для мобильных устройств и обычных компьютеров.
                                   Справка Яндекса и Гугла";
    $MESS["MORE_INFORMATION_2"] = "Sitemaps — XML-файлы с информацией для поисковых систем (таких как <a href=https:\\google.com>Google</a>, <a href=https:\\yandex.ru>Яндекс</a>, 
                                   <a href=https:\\bing.com>Bing</a>, <a href=https:\\mail.ru/>Поиск@Mail.Ru</a>) о страницах веб-сайта, 
                                   которые подлежат индексации. Sitemaps могут помочь поисковикам определить местонахождение страниц сайта, время их последнего обновления, 
                                   частоту обновления и важность относительно других страниц сайта для того, чтобы поисковая машина смогла более разумно индексировать сайт.
                                   Использование протокола Sitemaps не является гарантией того, что веб-страницы будут проиндексированы поисковыми системами, это всего лишь 
                                   дополнительная подсказка для сканеров, которые смогут выполнить более тщательное сканирование сайта.";
    $MESS["MORE_INFORMATION_3"] = "301 редирект (301 Permanent Redirect) – серверное перенаправление пользователей на другой URL адрес при смене адреса сайта, или адреса страницы.";
    $MESS["MORE_INFORMATION_4"] = "Ошибка 404 или Not Found («не найдено») — стандартный код ответа HTTP о том, что клиент был в состоянии общаться с сервером, но сервер не может найти данные согласно запросу.";
    $MESS["MORE_INFORMATION_5"] = "Ошибки типа \"Отказ в доступе\".";
    $MESS["MORE_INFORMATION_6"] = "HTTP — это протокол, в котором описаны правила передачи данных в интернете. 
                                   Он помогает браузеру загружать веб-страницы, а серверу — получить информацию, которую пользователь ввёл на сайте.
                                   HTTPS — это тот же протокол, но с надстройкой безопасности.";
    $MESS["MORE_INFORMATION_7"] = "Человеко Понятный Урл яляется вольным переводом английского термина «Search Engine Friendly URLs», 
                                   то есть, дружественные и красивые адреса.";

//дополнительные чекбоксы для 1
    $MESS["CHECK_1_1"] = "Закрыты служебные и ненужные разделы.";
    $MESS["CHECK_1_2"] = "Заданы разные User-Agent для Яндекса и других роботов.";
    $MESS["CHECK_1_3"] = "Задано главное зеркало для Яндекса.";
    $MESS["CHECK_1_4"] = "Закрыты страницы с динамическими параметрами.";
    $MESS["CHECK_1_5"] = "Указана ссылка на карту сайта для роботов.";
//дополнительные чекбоксы для 2
    $MESS["CHECK_2_1"] = "Задан адрес.";
    $MESS["CHECK_2_2"] = "Задана дата последнего изменения.";
    $MESS["CHECK_2_3"] = "Задана вероятная частота изменения.";
    $MESS["CHECK_2_4"] = "Задана приоритетность URL относительно других URL";
//дополнительные чекбоксы для 3
    $MESS["CHECK_3_1"] = "Использован mod_rewrite";
//дополнительные чекбоксы для 6
    $MESS["CHECK_6_1"] = "Установлен SSL-сертификат";
//дополнительные чекбоксы для 7
    $MESS["CHECK_7_1"] = "Организована структура ЧПУ";
?>